<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Kevin L. McKee</title>
    <link>https://kmckee90.github.io/posts/</link>
    <description>Recent content in Posts on Kevin L. McKee</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>kmckee90@gmail.com</managingEditor>
    <webMaster>kmckee90@gmail.com</webMaster>
    <lastBuildDate>Tue, 29 Jun 2021 18:30:52 +0000</lastBuildDate>
    <atom:link href="https://kmckee90.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>New position at CCNLab</title>
      <link>https://kmckee90.github.io/posts/ccnlab/</link>
      <pubDate>Tue, 29 Jun 2021 18:30:52 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/ccnlab/</guid>
      <description>&lt;p&gt;As of June 21, 2021 I have left my job as a biostatistician at Virginia Tech and joined UC Davis &lt;a href=&#34;https://ccnlab.org/&#34;&gt;Computational Cognitive Neuroscience lab&lt;/a&gt; lab as a postdoc! I cannot express how exciting it has been to discover this kind of research but to also land an opportunity to train and do it myself. The lab has a variety of ongoing research involving biologically-constrained spiking and rate coded neural networks in the &lt;a href=&#34;https://en.wikipedia.org/wiki/Leabra&#34;&gt;Leabra&lt;/a&gt; framework (&lt;a href=&#34;https://github.com/emer/leabra&#34;&gt;github&lt;/a&gt;). There is an excellent &lt;a href=&#34;https://compcogneuro.org/&#34;&gt;textbook written and published for free online&lt;/a&gt; by the PI, Randy O&amp;rsquo;Reilly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Binary neural nets in R, part 3: Recurrent Helmholtz Machine</title>
      <link>https://kmckee90.github.io/posts/recurrenthelmholtz/</link>
      <pubDate>Thu, 25 Mar 2021 09:38:21 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/recurrenthelmholtz/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/kmckee90/neural-networks&#34;&gt;github repository for this project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Part 3 of my neural network project in R involves coding a recurrent version of the Helmholtz machine. A recurrent (i.e., autoregressive or time-lagged) version of the network follows naturally (kind of), and of course, Hinton already published the idea in 1995. I used his paper as a guide to be sure nothing was markedly different about the approach and coded it according to my previous strategy.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stochastic resonance</title>
      <link>https://kmckee90.github.io/posts/stochastic-resonance/</link>
      <pubDate>Sat, 20 Mar 2021 22:42:13 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/stochastic-resonance/</guid>
      <description>&lt;p&gt;In digging through old models and scripts, I came upon one to illustrate the concept of &lt;a href=&#34;https://en.wikipedia.org/wiki/Stochastic_resonance#:~:text=Stochastic%20resonance%20(SR)%20is%20a,a%20wide%20spectrum%20of%20frequencies&#34;&gt;stochastic resonance&lt;/a&gt;.&#xA;In short, when noise is added to periodic signals with local stability, it can cause them to jump between equilibria at about the dominant frequency:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://kmckee90.github.io/sr.gif&#34; alt=&#34;Stochastic Resonance Animation&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;We are always looking for interesting statistical phenomena like this for models in computational psychiatry, where symptoms of mania or depression, for example, are often episodic and make large, spontaneous leaps after periods of relative stability.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Discretization in 3 languages</title>
      <link>https://kmckee90.github.io/posts/discretization/</link>
      <pubDate>Sat, 20 Mar 2021 21:47:13 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/discretization/</guid>
      <description>&lt;p&gt;There is an obscure and useful function that makes it easy to fit stochastic differential equations to data insofar as the model can be linearized without causing too much trouble. The function discretizes the continuous-time (i.e., differential equation) state matrices &lt;code&gt;A&lt;/code&gt;, the drift or state transition matrix, &lt;code&gt;B&lt;/code&gt;, the input or covariate coefficient matrix, and &lt;code&gt;Q&lt;/code&gt;, diffusion or noise covariance matrix. That means that the function essentially takes the differential equation in matrix form and solves it for a given time step. The discretized matrices function like those of an autoregressive process. Some details of this approach and what this does can be found &lt;a href=&#34;https://en.wikipedia.org/wiki/Discretization&#34;&gt;here&lt;/a&gt; but not exactly a complete implementation, namely with matrix &lt;code&gt;B&lt;/code&gt;. So this is one of those code blocks I just have backed up in several project folders in various languages.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding MCMC and autodifferentiation</title>
      <link>https://kmckee90.github.io/posts/edu1/</link>
      <pubDate>Fri, 19 Mar 2021 10:11:35 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/edu1/</guid>
      <description>&lt;p&gt;In putting together educational materials related to Stan and posterior sampling, I remembered two good ones.&lt;/p&gt;&#xA;&lt;p&gt;The &lt;a href=&#34;https://chi-feng.github.io/mcmc-demo/app.html&#34;&gt;MCMC interactive gallery&lt;/a&gt; is the best set of MCMC visualizations I&amp;rsquo;ve found.&lt;/p&gt;&#xA;&lt;p&gt;Stan uses NUTS, so it has to calculate numerous gradients for each new sample and does so by autodifferentiation.&#xA;I recommend &lt;a href=&#34;https://www.youtube.com/embed/wG_nF1awSSY&#34;&gt;this video&lt;/a&gt; for understanding autodiff.&#xA;It helps a lot to know what Stan is doing with the model code to avoid giving it more work than necessary.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stan: Structural Ordinal Item Response Theory with a Latent Interaction</title>
      <link>https://kmckee90.github.io/posts/ordinalirt/</link>
      <pubDate>Fri, 19 Mar 2021 08:55:22 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/ordinalirt/</guid>
      <description>&lt;p&gt;The Non-Gaussian factor model introduces the idea of using other distributions for a factor analysis. But that code is not very generalized, and in reality we&amp;rsquo;ll tend to need something more like structural equation modeling with non-Gaussian variables.&lt;/p&gt;&#xA;&lt;p&gt;The name for a factor model with logit-linked indicators, whether dichotomous or ordinal, is Item Response Theory. It has been used for decades to develop instruments and in particular, tests. Because of its history, factor loadings are called the &amp;ldquo;discrimination&amp;rdquo; parameters, intercepts are the item &amp;ldquo;difficulty&amp;rdquo;, and the factor scores represent each person&amp;rsquo;s &amp;ldquo;ability&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stan: Non-Normal Factor Model</title>
      <link>https://kmckee90.github.io/posts/nongaussianfa/</link>
      <pubDate>Fri, 19 Mar 2021 08:43:04 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/nongaussianfa/</guid>
      <description>&lt;p&gt;There are so many factor analyses in the world and so few truly normally distributed variables. I have not seen much careful tailoring of residual distributions in medical or psychological research. It is probably because most software don&amp;rsquo;t support it or make it convenient. It was a revelation to me that you can use Markov Chain Monte Carlo (MCMC) to sample latent variables and then do all kinds of things, like non-Gaussian distributions and latent variable interactions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Binary neural nets in R, part 2: Helmholtz Machine</title>
      <link>https://kmckee90.github.io/posts/hm1/</link>
      <pubDate>Thu, 18 Mar 2021 16:49:12 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/hm1/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/kmckee90/neural-networks&#34;&gt;github source for this project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;In the last post, I looked at coding a restricted Boltzmann machine (RBM) in R. In this one, I will compare the algorithm and its results to the Helmholtz Machine, which uses the wake-sleep algorithm.&lt;/p&gt;&#xA;&lt;p&gt;The basic idea behind the wake-sleep algorithm is that the model learns in two alternating phases. In the wake phase, random values for the hidden nodes are generated according to the expectations of the recognition network, then the generative network weights are adjusted.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Binary neural nets in R, part 1: Restricted Boltzmann Machine</title>
      <link>https://kmckee90.github.io/posts/rbm1/</link>
      <pubDate>Wed, 17 Mar 2021 18:55:25 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/rbm1/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/kmckee90/neural-networks&#34;&gt;github source for this project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;For most statistical models, you can verify that they work by simulating data from a set of parameter values, then fitting the model to the simulated data and seeing how well it recovers those values. With artificial neural networks it is common to have many local solutions and a stochastic learning algorithm, so while an ANN may find an good solution on the simulated data, it is far less likely to match the data-generating parameters.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Painting a harpsichord lid</title>
      <link>https://kmckee90.github.io/posts/harpsichordprocess/</link>
      <pubDate>Fri, 12 Mar 2021 21:40:23 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/harpsichordprocess/</guid>
      <description>&lt;p&gt;Some process photos from my painting on a harpsichord lid. (I&amp;rsquo;m using this post to figure out getting images into blog posts and such.)&lt;/p&gt;&#xA;&lt;p&gt;I painted this harpsichord lid for a commission in 2016. I started with a photoshop mockup:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://kmckee90.github.io/img/art/harpsichord_process/0.jpg&#34; alt=&#34;Harpsichord Process 0&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;The first stages of the actual painting are interesting to look back on because they show how fundamental color and movement are to the composition:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://kmckee90.github.io/img/art/harpsichord_process/1.jpg&#34; alt=&#34;Harpsichord Process 1&#34;&gt;&#xA;&lt;img src=&#34;https://kmckee90.github.io/img/art/harpsichord_process/2.jpg&#34; alt=&#34;Harpsichord Process 2&#34;&gt;&#xA;&lt;img src=&#34;https://kmckee90.github.io/img/art/harpsichord_process/3.jpg&#34; alt=&#34;Harpsichord Process 3&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Art</title>
      <link>https://kmckee90.github.io/posts/art/</link>
      <pubDate>Fri, 12 Mar 2021 21:13:28 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/art/</guid>
      <description>&lt;p&gt;Art gallery now works. Woohoo!&lt;/p&gt;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&lt;div class=&#34;gallery caption-position-bottom caption-effect-slide hover-effect-zoom hover-transition&#34; itemscope itemtype=&#34;http://schema.org/ImageGallery&#34;&gt;&#xD;&#xA;&#x9;  &#xD;&#xA;&#xD;&#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;https://kmckee90.github.io/css/hugo-easy-gallery.css&#34; /&gt;&#xD;&#xA;&lt;div class=&#34;box&#34; &gt;&#xD;&#xA;  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;&#xD;&#xA;    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://kmckee90.github.io//img/art/11.jpg&#39;);&#34;&gt;&#xD;&#xA;      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://kmckee90.github.io/img/art/11.jpg&#34; alt=&#34;Painting 11&#34;/&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;a href=&#34;https://kmckee90.github.io/img/art/11.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;&#xD;&#xA;  &lt;/figure&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&lt;div class=&#34;box&#34; &gt;&#xD;&#xA;  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;&#xD;&#xA;    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://kmckee90.github.io//img/art/12.jpg&#39;);&#34;&gt;&#xD;&#xA;      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://kmckee90.github.io/img/art/12.jpg&#34; alt=&#34;Painting 12&#34;/&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;a href=&#34;https://kmckee90.github.io/img/art/12.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;&#xD;&#xA;  &lt;/figure&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&lt;div class=&#34;box&#34; &gt;&#xD;&#xA;  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;&#xD;&#xA;    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://kmckee90.github.io//img/art/13.jpg&#39;);&#34;&gt;&#xD;&#xA;      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://kmckee90.github.io/img/art/13.jpg&#34; alt=&#34;Painting 13&#34;/&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;a href=&#34;https://kmckee90.github.io/img/art/13.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;&#xD;&#xA;  &lt;/figure&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://kmckee90.github.io/art/&#34;&gt;Check out the paintings&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>First post</title>
      <link>https://kmckee90.github.io/posts/first/</link>
      <pubDate>Thu, 11 Mar 2021 21:40:23 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/first/</guid>
      <description>&lt;p&gt;As of this first post, I&amp;rsquo;ll be using this site to document my various projects, code, minor discoveries, or other thoughts that probably won&amp;rsquo;t be published anywhere else.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

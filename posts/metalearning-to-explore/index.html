

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>Learning to Explore Smarter and Faster - </title>

  <meta name="description" content="
Exploration is the drum beat of any intelligent, self-improving system.


  
  
  

Key:
Red: visited locations. 
Yellow: Last path taken.
Cyan: Lowest-density frontier.
Most modern AI systems are built on machine learning, and machine learning achieves nothing without good, comprehensive data about its task.
That&rsquo;s why I&rsquo;ve written a new paper, Meta-learning to Explore via Memory Density Feedback, demonstrating an improved approach to autonomous exploration.
Watch above as the new RL-based agent, able to see only its own current coordinates and output movements, nonetheless learns to rapidly probe various maze problems, pushing its frontier and returning to lesser visited areas along the way."><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Kevin L. McKee",
    
    "url": "https:\/\/kmckee90.github.io\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/kmckee90.github.io\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/kmckee90.github.io\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/kmckee90.github.io\/posts\/metalearning-to-explore\/",
          "name": "Learning to explore smarter and faster"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : ""
  },
  "headline": "Learning to Explore Smarter and Faster",
  "description" : " Exploration is the drum beat of any intelligent, self-improving system.\nKey: Red: visited locations. Yellow: Last path taken. Cyan: Lowest-density frontier.\nMost modern AI systems are built on machine learning, and machine learning achieves nothing without good, comprehensive data about its task. That\u0026rsquo;s why I\u0026rsquo;ve written a new paper, Meta-learning to Explore via Memory Density Feedback, demonstrating an improved approach to autonomous exploration. Watch above as the new RL-based agent, able to see only its own current coordinates and output movements, nonetheless learns to rapidly probe various maze problems, pushing its frontier and returning to lesser visited areas along the way.\n",
  "inLanguage" : "en",
  "wordCount":  619 ,
  "datePublished" : "2025-09-18T10:47:52-04:00",
  "dateModified" : "2025-09-18T10:47:52-04:00",
  "image" : "https:\/\/kmckee90.github.io\/",
  "keywords" : [ "" ],
  "mainEntityOfPage" : "https:\/\/kmckee90.github.io\/posts\/metalearning-to-explore\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/kmckee90.github.io\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/kmckee90.github.io\/",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="Learning to Explore Smarter and Faster" />
<meta property="og:description" content="
Exploration is the drum beat of any intelligent, self-improving system.


  
  
  

Key:
Red: visited locations. 
Yellow: Last path taken.
Cyan: Lowest-density frontier.
Most modern AI systems are built on machine learning, and machine learning achieves nothing without good, comprehensive data about its task.
That&rsquo;s why I&rsquo;ve written a new paper, Meta-learning to Explore via Memory Density Feedback, demonstrating an improved approach to autonomous exploration.
Watch above as the new RL-based agent, able to see only its own current coordinates and output movements, nonetheless learns to rapidly probe various maze problems, pushing its frontier and returning to lesser visited areas along the way.">
<meta property="og:url" content="https://kmckee90.github.io/posts/metalearning-to-explore/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Kevin L. McKee" />

  <meta name="twitter:title" content="Learning to Explore Smarter and Faster" />
  <meta name="twitter:description" content="
Exploration is the drum beat of any intelligent, self-improving system.


  
  
  

Key:
Red: visited locations. 
Yellow: Last path taken.
Cyan: Lowest-density frontier.
Most modern AI systems are â€¦&lt;/!--&gt;&lt;/!--&gt;">
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="generator" content="Hugo 0.150.0">
  <link rel="alternate" href="https://kmckee90.github.io/index.xml" type="application/rss+xml" title="Kevin L. McKee"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="https://kmckee90.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://kmckee90.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://kmckee90.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">

  </head>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', () => {
  renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false},
      {left: '\\(', right: '\\)', display: false},
      {left: '\\[', right: '\\]', display: true}
    ]
  });
});
</script>

  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('pre > code.language-mermaid').forEach((code) => {
    const pre = code.parentElement;
    const wrapper = document.createElement('div');
    wrapper.style.textAlign = 'center';
    const diagram = document.createElement('div');
    diagram.className = 'mermaid';
    diagram.textContent = code.textContent;
    wrapper.appendChild(diagram);
    pre.replaceWith(wrapper);
  });

  mermaid.initialize({
    startOnLoad: true,
    securityLevel: 'loose',
    theme: window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default'
  });
});
</script>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://kmckee90.github.io/">Kevin L. McKee</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Home" href="/">Home</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/about">About</a>
            </li>
          
        
          
            <li>
              <a title="Research" href="/research">Research</a>
            </li>
          
        
          
            <li>
              <a title="Code" href="/code">Code</a>
            </li>
          
        
          
            <li>
              <a title="Art" href="/art">Art</a>
            </li>
          
        

        

        
      </ul>
    </div>

    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="posts-heading">
              
                <h1>Learning to Explore Smarter and Faster</h1>
              
              
                <hr class="small">
              
              
              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>

    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <!-- Hook intro:  -->
<p>Exploration is the drum beat of any intelligent, self-improving system.</p>
<!-- Videos:  -->
<div style="display:flex; gap:0; padding:0; margin:0;">
  <video src="/m2e/fixed.webm" style="width:33.333%; height:auto; display:block;" autoplay muted loop playsinline controls></video>
  <video src="/m2e/continual.webm" style="width:33.333%; height:auto; display:block;" autoplay muted loop playsinline controls></video>
  <video src="/m2e/random.webm" style="width:33.333%; height:auto; display:block;" autoplay muted loop playsinline controls></video>
</div>
<p>Key:
<span style="color:red;">Red: visited locations. </span>
<span style="color:#ffff00;">Yellow: Last path taken.</span>
<span style="color:#00ffff;">Cyan: Lowest-density frontier.</span></p>
<p>Most modern AI systems are built on machine learning, and machine learning achieves nothing without good, comprehensive data about its task.
That&rsquo;s why I&rsquo;ve written a new paper, <a href="https://arxiv.org/abs/2503.02831">Meta-learning to Explore via Memory Density Feedback</a>, demonstrating an improved approach to autonomous exploration.
Watch above as the new RL-based agent, able to see only its own current coordinates and output movements, nonetheless learns to rapidly probe various maze problems, pushing its frontier and returning to lesser visited areas along the way.</p>
<!--  How it works -->
<p>The innovation behind this agent is its use of memory and feedback to make intelligent decisions even when it has ventured beyond its training distribution.
It uses reinforcement learning with an internally generated reward: roughly the negative probability density of what it sees now, given the distribution of what it has seen before.
In other words, it is rewarded by unfamiliar experiences.
But that alone is standard practice for exploration algorithms.
Where this one differs is that it evaluates the familiarity of what it sees in real time.
That familiarity score and the associated actions it took feed back to it as input.
When the agent processes a good running memory of its inputs, it can feel its way around the landscape of familiar experiences.
On simple maze tasks, the solution it learns is a bit like gradient descent over its own memory distribution.</p>
<p>This system has several benefits over the preeminent <a href="https://arxiv.org/abs/1901.10995">Go-Explore</a> type algorithm.
On tasks with fixed, repeatable paths (<strong>the left-hand video</strong>), its progress accelerates as it learns more efficient strategies.
It learns to maximize the amount of <em>new progress per episode</em>, often showing large leaps into new areas.
But suppose the task is not repeatable because the agent never restarts to a familiar point (<strong>center video</strong>).
In that case, the agent can use its training, memory, and feedback to backtrack and relocate unexplored paths.
Suppose the task is not repeatable because the paths change unpredictably with every episode (<strong>right-hand video</strong>).
The agent learns to rely less on the observations themselves, and more on the feedback it gets as it experiments with different actions.
In that demo, you can see that as training goes on, its exploration progresses despite unpredictable re-arrangements of the walls.</p>
<p>There is another mechanism at play: offline reinforcement learning as planning.
The training is just DQN, which involves replaying episodes and incrementing the value of each action that better maximized the temporally discounted* rewards.
But when the initial hidden state of the replayed sequences is artificially set to be the explorer&rsquo;s current state, this offline training doubles as a planning, synthesizing an action policy that will move the agent from its current location back to the frontier.
By storing every episode that broke its own exploration record in a special, separate training database, it can re-train and plan on a stable recollection of the entire frontier.
Lingering on a single goal direction too long does not cause it to forget previous, viable paths.</p>
<p>While the mazes above are crude, toy examples, they represent the general graph decision-making problem that RL agents are faced with.
Take for instance, the same algorithm deployed to the RL testing game <a href="https://github.com/danijar/crafter">Crafter</a>:</p>
<br>
<div style="display:flex; justify-content:center; gap:0; padding:0; margin:0;">
  <video src="/m2e/crafter_exploration.webm" style="width:50%; height:auto; display:block;" autoplay muted loop playsinline controls></video>
</div>
<p>Of course, the goal of crafter is not to sprint around like a headless chicken, so the next steps are to decide on how to best balance Crafter&rsquo;s reward system against the intrinsic exploration, such that the agent optimally alternates between them.
Once integrated, the agent should train much faster, as its initial attainment of achievements and tools will no longer be totally left to chance.</p>
<hr>
<p>*See <a href="http://incompleteideas.net/book/the-book-2nd.html">Sutton and Barto</a> for the complete RL basics.</p>


        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=https%3a%2f%2fkmckee90.github.io%2fposts%2fmetalearning-to-explore%2f&amp;text=Learning%20to%20Explore%20Smarter%20and%20Faster&amp;via=" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fkmckee90.github.io%2fposts%2fmetalearning-to-explore%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=https%3a%2f%2fkmckee90.github.io%2fposts%2fmetalearning-to-explore%2f&amp;title=Learning%20to%20Explore%20Smarter%20and%20Faster" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fkmckee90.github.io%2fposts%2fmetalearning-to-explore%2f&amp;title=Learning%20to%20Explore%20Smarter%20and%20Faster" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fkmckee90.github.io%2fposts%2fmetalearning-to-explore%2f&amp;title=Learning%20to%20Explore%20Smarter%20and%20Faster" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fkmckee90.github.io%2fposts%2fmetalearning-to-explore%2f&amp;description=Learning%20to%20Explore%20Smarter%20and%20Faster" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://kmckee90.github.io/posts/snn-demo/" data-toggle="tooltip" data-placement="top" title="What kind of algorithms run in a soup?">&larr; Previous Post</a>
            </li>
          
          
        </ul>
      


      
      
      
      
      
        
      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
		
		  <a href="mailto:kmckee90@gmail.com" title="Email me">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://github.com/kmckee90" title="GitHub">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://linkedin.com/in/kevin-mckee-18a2561a0" title="LinkedIn">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2025
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://kmckee90.github.io/">Kevin L. McKee</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.150.0</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="https://kmckee90.github.io/js/main.js"></script>
<script src="https://kmckee90.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://kmckee90.github.io/js/load-photoswipe.js"></script>










    
  </body>
</html>


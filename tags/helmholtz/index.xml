<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Helmholtz on Kevin L. McKee</title>
    <link>https://kmckee90.github.io/tags/helmholtz/</link>
    <description>Recent content in Helmholtz on Kevin L. McKee</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>kmckee90@gmail.com</managingEditor>
    <webMaster>kmckee90@gmail.com</webMaster>
    <lastBuildDate>Thu, 18 Mar 2021 16:49:12 +0000</lastBuildDate>
    <atom:link href="https://kmckee90.github.io/tags/helmholtz/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Binary neural nets in R, part 2: Helmholtz Machine</title>
      <link>https://kmckee90.github.io/posts/hm1/</link>
      <pubDate>Thu, 18 Mar 2021 16:49:12 +0000</pubDate><author>kmckee90@gmail.com</author>
      <guid>https://kmckee90.github.io/posts/hm1/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/kmckee90/neural-networks&#34;&gt;github source for this project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;In the last post, I looked at coding a restricted Boltzmann machine (RBM) in R. In this one, I will compare the algorithm and its results to the Helmholtz Machine, which uses the wake-sleep algorithm.&lt;/p&gt;&#xA;&lt;p&gt;The basic idea behind the wake-sleep algorithm is that the model learns in two alternating phases. In the wake phase, random values for the hidden nodes are generated according to the expectations of the recognition network, then the generative network weights are adjusted.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
